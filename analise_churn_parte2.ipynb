{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Desafio Telecom X - Parte 2: Previsão de Churn com Machine Learning\n",
        "\n",
        "## 1. Introdução\n",
        "\n",
        "O objetivo deste projeto é construir e avaliar modelos de Machine Learning capazes de prever a evasão de clientes (churn) em uma empresa de telecomunicações. A partir dos dados tratados na Parte 1, o foco é preparar os dados para modelagem, treinar diferentes algoritmos, avaliar suas performances e, por fim, extrair insights sobre os principais fatores que influenciam a decisão de um cliente cancelar o serviço."
      ],
      "metadata": {
        "id": "_EUuehfVJfvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Importação e Carregamento dos Dados ---\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/dados_tratados.csv')\n",
        "\n",
        "# --- 2. Pré-processamento ---\n",
        "df = df.drop('customerID', axis=1)\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# --- 3. Separação de Features (X) e Alvo (y) ---\n",
        "X = df_encoded.drop('Churn', axis=1)\n",
        "y = df_encoded['Churn']\n",
        "\n",
        "# --- 4. Divisão em Dados de Treino e Teste ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- 5. Scaling dos Dados (NOVO PASSO!) ---\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cria o objeto scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# \"Aprende\" a escala com os dados de TREINO e os transforma\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Apenas transforma os dados de TESTE com a mesma escala aprendida\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "print(\"Dados preparados, divididos e escalados com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUxnU8ChJoMY",
        "outputId": "6c1c5591-2556-4850-c88c-045d6e122c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados preparados, divididos e escalados com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Treinamento e Avaliação dos Modelos\n",
        "\n",
        "Nesta etapa, dois modelos de classificação foram treinados e avaliados para determinar qual possui a melhor performance na previsão de churn."
      ],
      "metadata": {
        "id": "sHJIBl6qJvan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Modelo 1: Regressão Logística ---\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Instancia o modelo (max_iter não é mais tão crítico, mas podemos manter)\n",
        "modelo_logistico = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# ATENÇÃO: Usando os dados escalados (scaled) para treinar\n",
        "modelo_logistico.fit(X_train_scaled, y_train)\n",
        "\n",
        "# E usando os dados de teste escalados para prever\n",
        "previsoes_logistico = modelo_logistico.predict(X_test_scaled)\n",
        "\n",
        "print(\"--- Resultados do Modelo de Regressão Logística ---\")\n",
        "print(f\"Acurácia: {accuracy_score(y_test, previsoes_logistico) * 100:.2f}%\")\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, previsoes_logistico))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG5wv4K0JwV7",
        "outputId": "6c91ea1a-2ad3-4c61-dee8-fcccb271d0d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Resultados do Modelo de Regressão Logística ---\n",
            "Acurácia: 79.60%\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86      1033\n",
            "           1       0.64      0.54      0.58       374\n",
            "\n",
            "    accuracy                           0.80      1407\n",
            "   macro avg       0.74      0.71      0.72      1407\n",
            "weighted avg       0.79      0.80      0.79      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Modelo 2: Random Forest ---\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Instancia e treina o modelo\n",
        "modelo_floresta = RandomForestClassifier(random_state=42)\n",
        "modelo_floresta.fit(X_train, y_train)\n",
        "\n",
        "# Faz as previsões e avalia o modelo\n",
        "previsoes_floresta = modelo_floresta.predict(X_test)\n",
        "\n",
        "print(\"--- Resultados do Modelo Random Forest ---\")\n",
        "print(f\"Acurácia: {accuracy_score(y_test, previsoes_floresta) * 100:.2f}%\")\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, previsoes_floresta))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhmqcPkOJ65d",
        "outputId": "e4fc11c1-305f-42d2-becd-5223c553e696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Resultados do Modelo Random Forest ---\n",
            "Acurácia: 77.75%\n",
            "\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85      1033\n",
            "           1       0.61      0.46      0.52       374\n",
            "\n",
            "    accuracy                           0.78      1407\n",
            "   macro avg       0.71      0.68      0.69      1407\n",
            "weighted avg       0.76      0.78      0.77      1407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Análise do Melhor Modelo e Fatores de Influência\n",
        "\n",
        "Após comparar os modelos, a Regressão Logística foi escolhida por ter um melhor desempenho na métrica de recall para a classe \"churn\". Agora, vamos investigar quais fatores (features) este modelo considerou mais importantes para tomar suas decisões."
      ],
      "metadata": {
        "id": "rjeyECAuKAKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrai os coeficientes do modelo de Regressão Logística\n",
        "feature_names = X.columns\n",
        "coeficientes = modelo_logistico.coef_[0]\n",
        "\n",
        "# Cria um DataFrame para visualizar a importância de cada fator\n",
        "importancia_features = pd.DataFrame({'Fator': feature_names, 'Peso': coeficientes})\n",
        "\n",
        "# Ordena os fatores pela sua importância (valor absoluto do peso)\n",
        "importancia_features['Importancia'] = importancia_features['Peso'].abs()\n",
        "importancia_ordenada = importancia_features.sort_values(by='Importancia', ascending=False)\n",
        "importancia_ordenada = importancia_ordenada.drop(columns='Importancia')\n",
        "\n",
        "print(\"--- Fatores que Mais Influenciam o Churn (do maior para o menor impacto) ---\")\n",
        "print(\"Pesos positivos aumentam a chance de Churn. Pesos negativos diminuem a chance de Churn.\")\n",
        "print(importancia_ordenada.head(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AsWJ_ZGKBPc",
        "outputId": "98a6a2eb-b229-475e-a250-292ddd3c8520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fatores que Mais Influenciam o Churn (do maior para o menor impacto) ---\n",
            "Pesos positivos aumentam a chance de Churn. Pesos negativos diminuem a chance de Churn.\n",
            "                             Fator      Peso\n",
            "1                           tenure -1.504375\n",
            "3                    Charges.Total  0.762711\n",
            "25               Contract_Two year -0.611861\n",
            "10     InternetService_Fiber optic  0.549261\n",
            "2                  Charges.Monthly -0.445468\n",
            "24               Contract_One year -0.297896\n",
            "28  PaymentMethod_Electronic check  0.181594\n",
            "26            PaperlessBilling_Yes  0.176807\n",
            "9                MultipleLines_Yes  0.176481\n",
            "21                 StreamingTV_Yes  0.155072\n",
            "23             StreamingMovies_Yes  0.152699\n",
            "13              OnlineSecurity_Yes -0.146230\n",
            "19                 TechSupport_Yes -0.120072\n",
            "0                    SeniorCitizen  0.087943\n",
            "6                   Dependents_Yes -0.079903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Conclusão e Recomendações Estratégicas\n",
        "\n",
        "### Resumo do Projeto\n",
        "O objetivo deste projeto foi desenvolver um modelo de machine learning para prever a evasão de clientes (churn) na empresa Telecom X e identificar os principais fatores que influenciam essa decisão.\n",
        "\n",
        "### Desempenho e Escolha do Modelo\n",
        "Foram treinados e avaliados dois modelos de classificação: Regressão Logística e Random Forest. O modelo de **Regressão Logística foi escolhido como o melhor**, pois apresentou um desempenho superior na tarefa mais crítica para o negócio: identificar clientes com risco real de churn, atingindo um **recall de 54%** para a classe de churners, contra 46% do Random Forest.\n",
        "\n",
        "### Principais Insights\n",
        "A análise do modelo campeão revelou os principais fatores de risco e retenção. Os clientes com maior probabilidade de cancelar são aqueles com **internet de Fibra Óptica** e que utilizam **meios de pagamento e faturamento digitais**. Em contrapartida, o fator de maior peso para a retenção de um cliente é a adesão a **contratos de longo prazo (1 e 2 anos)**, seguido pela contratação de serviços de **suporte e segurança**.\n",
        "\n",
        "### Recomendações Estratégicas\n",
        "Com base nos insights, as seguintes ações são recomendadas:\n",
        "1.  **Fidelização por Contrato:** Criar campanhas de marketing agressivas para incentivar clientes de planos mensais a migrarem para contratos de 1 ou 2 anos, oferecendo descontos ou benefícios claros.\n",
        "2.  **Investigar o Serviço de Fibra:** Realizar uma análise aprofundada (ex: pesquisa de satisfação) com os clientes de Fibra Óptica para entender a causa da alta evasão. O problema está no preço, na qualidade do serviço ou na forte concorrência?\n",
        "3.  **Agregar Valor com Segurança:** Promover pacotes que incluam Suporte Técnico e Segurança Online como diferenciais, uma vez que estes serviços provaram ser importantes para a retenção."
      ],
      "metadata": {
        "id": "vrLCH5-FKInq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3d29HUAmKMML"
      }
    }
  ]
}